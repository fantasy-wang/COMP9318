{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9318 Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. This note book contains instructions for **COMP9318-Lab4**.\n",
    "\n",
    "* You are required to complete your implementation in a file `submission.py` provided along with this notebook.\n",
    "\n",
    "* You are not allowed to print out unnecessary stuff. We will not consider any output printed out on the screen. All results should be returned in appropriate data structures via corresponding functions.\n",
    "\n",
    "* You can submit your implementation for **Lab4** via following link: https://unswkg.net/submit/ .\n",
    "\n",
    "* For each question, we have provided you with detailed instructions along with question headings. In case of any problem, you can post your query @ Piazza.\n",
    "\n",
    "* You are allowed to add other functions and/or import modules (you may have to in this lab), but you are not allowed to define global variables. **Only functions are allowed** in `submission.py`. \n",
    "\n",
    "* You should not import unnecessary modules/libraries, failing to import such modules at test time will lead to errors.\n",
    "\n",
    "* We will provide immediate feedback on your submission. You can access your scores using the online submission portal on the same day. \n",
    "\n",
    "* For **Final Evaluation** we will be using a different dataset, so your final scores may vary.  \n",
    "\n",
    "* You are allowed to submit as many times as you want before the deadline, but **ONLY the latest version will be kept and marked**.\n",
    "\n",
    "* Submission deadline for this assignment is **20:59:59 on 20th April, 2020 (SYDNEY TIME)**. We will **not** accept any late submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-1: Text Classification using Multinomial Naive Bayes\n",
    "\n",
    "You are required to implement a multinomial naive bayes classifier to predict spam SMS.\n",
    "\n",
    "The training data is a set of SMS categoried into `spam` and `ham`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv('./asset/data.txt', sep='\\t')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement a unigram model, first we tokenize the text. We use the count corresponding to each token (word) in the SMS as its feature (i.e., bag of words). We store the features and catrgorical information for each SMS in a `dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sms):\n",
    "    return sms.split(' ')\n",
    "\n",
    "def get_freq_of_tokens(sms):\n",
    "    tokens = {}\n",
    "    for token in tokenize(sms):\n",
    "        if token not in tokens:\n",
    "            tokens[token] = 1\n",
    "        else:\n",
    "            tokens[token] += 1\n",
    "    return tokens\n",
    "\n",
    "training_data = []\n",
    "for index in range(len(raw_data)):\n",
    "    training_data.append((get_freq_of_tokens(raw_data.iloc[index].text), raw_data.iloc[index].category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'not', 'spam']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(sms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, you need to **implement** a multinomial naive bayes classifier (i.e., `multinomial_nb()` in the file: `submission.py`) with add-1 smoothing. The input arguments of `multinomial_nb()` are:\n",
    "* `training_data`: pre-processed data stored as a `dictionary`\n",
    "* `sms`: test-sms (i.e., a list of tokens) that you need to categorize as `spam` and/or `ham`\n",
    "\n",
    "The return value of `multinomial_nb()` should be the **ratio** of the probability of sms is spam and the probability of sms is ham. A return value larger than 1 implies the `sms` is spam and vice versa.\n",
    "\n",
    "For example, a sample output is shown in the cell given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2342767295597484\n"
     ]
    }
   ],
   "source": [
    "## How we test your implementation...\n",
    "import submission_ans as submission\n",
    "\n",
    "sms = 'I am not spam'\n",
    "print(submission.multinomial_nb(training_data, tokenize(sms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Test Environment\n",
    "\n",
    "For testing, we have pre-installed the requisite modules and/or libraries in the testing environment. You are only allowed to use following libraries:\n",
    "* python: 3.6.5\n",
    "* pandas: 0.19.2\n",
    "\n",
    "NOTE: You are required to implement the classifier by yourself. You are not allowed to import **sklearn** and/or any other library in Lab4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = ['I', 'am', 'not', 'spam']\n",
    "def multinomial_nb(training_data, sms):\n",
    "    \n",
    "    # prevent x not in training_data\n",
    "    smooth = 1\n",
    "    voc = set()\n",
    "    num = {'ham': 0, 'spam': 0}\n",
    "    prior = {'ham': 0, 'spam': 0}\n",
    "    sentence = {'spam':{},'ham':{}}\n",
    "    \n",
    "    for data in training_data:\n",
    "        prior[data[1]] += 1\n",
    "        for index in data[0]:\n",
    "            num[data[1]] += data[0][index]\n",
    "            voc.add(index)\n",
    "            if index in sentence[data[1]]:\n",
    "                sentence[data[1]][index] += data[0][index]\n",
    "            else:\n",
    "                sentence[data[1]][index] = data[0][index]\n",
    "    # probability of 'ham'\n",
    "    prob0 = prior['ham'] / len(training_data)\n",
    "    # probability of 'spam'\n",
    "    prob1 = prior['spam'] / len(training_data)\n",
    "    result = {'ham': prob0, 'spam': prob1}\n",
    "    \n",
    "\n",
    "    for token in sms:\n",
    "        if token in voc:\n",
    "            for key in sentence:\n",
    "                if token in sentence[key]:\n",
    "                    conditional_prob = (sentence[key][token] + smooth) / (num[key] + len(voc))\n",
    "                else:\n",
    "                    conditional_prob = ( smooth) / (num[key] + len(voc))\n",
    "                result[key] *= conditional_prob\n",
    "    return result['spam'] / result['ham']\n",
    "\n",
    "    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23427672955974846"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_nb(training_data, sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data):\n",
    "    smooth = 1\n",
    "    vocabulary = set()\n",
    "    data_value = {'spam':0,'ham':0}\n",
    "    data_set= {'spam':[],'ham':[]}\n",
    "    prior_prob = {'spam':0,'ham':0}\n",
    "    conditional_prob = dict()\n",
    "\n",
    "\n",
    "    for data in training_data:\n",
    "        prior_prob[data[1]] += 1\n",
    "        data_value[data[1]] += sum(data[0].values())\n",
    "        for i in data[0].items():\n",
    "            data_set[data[1]].append(i)\n",
    "            vocabulary.add(i[0])\n",
    "    # print(len(vocabulary))\n",
    "    prior_prob['spam'] /=  len(training_data)\n",
    "    prior_prob['ham'] /= len(training_data)\n",
    "    # print(prior_prob)\n",
    "#     print(data_value)\n",
    "#     print(data_set)\n",
    "\n",
    "    print(len(voc))\n",
    "    for data in training_data:\n",
    "        for i in data[0]:\n",
    "            print(i)\n",
    "            for j in ('spam', 'ham'):\n",
    "                print(j)\n",
    "                t = 0\n",
    "                for x in data_set[j]:\n",
    "                    if x[0] == i:\n",
    "                        t += x[1]\n",
    "                print(t)\n",
    "                temp = data_value[j] + len(vocabulary)\n",
    "                print(temp)\n",
    "                conditional_prob[(i, j)] = (sum([x[1] for x in data_set[j] if x[0] == i]) + smooth )/ ((data_value[j] + len(vocabulary)))\n",
    "    print(data_value)\n",
    "    return vocabulary, conditional_prob, prior_prob\n",
    "\n",
    "def predict(sms ,vocabulary, conditional_prob, prior_prob):\n",
    "    result ={'spam': prior_prob['spam'], 'ham': prior_prob['ham']}\n",
    "    for token in sms:\n",
    "        if token in vocabulary:\n",
    "            print(f'The token is {token}')\n",
    "            for i in ['spam', 'ham']:\n",
    "                # print((token,i),':' ,conditional_prob[(token,i)])\n",
    "                print(f'The result[{i}] is {result[i]}')\n",
    "                print(f'The {(token, i)} is {conditional_prob[(token, i)]}')\n",
    "                result[i] *= conditional_prob[(token, i)]\n",
    "                print(f'The result[{i}] is {result[i]}')\n",
    "    # print(result['spam'])\n",
    "    # print(result['ham'])\n",
    "    return result['spam']/ result['ham']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
